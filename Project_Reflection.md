# Project Reflection
------------------------------------



# 1 EDA - Cameron Meekums-Spence
In this project, we were given a dataset that contained geographic data across several variables, including temperature, precipitation, wind speed, coordinates, radiation and solar flux. All data was confined to one individual location near Manchester, UK. The data spanned from 2006 to 2080, with the variables modelled into the future. We were asked to provide a presentation in our groups on the dataset. The guidance for this project was minimal, meaning we had to use our initiative to steer the project and provide an outcome.

I decided to take some initiative in the organisation of this project and arranged our first meeting, completing an initial EDA before the meeting and sending it to the group, giving everyone a chance to digest beforehand. This allowed us to discuss any initial impressions and delegate tasks effectively.

The EDA relied on pandas and seaborn packages to visualise the data, whilst the ‘time’ column in the data was converted to datetime format to aid the timeseries plots Initially. I produced some summary statistics and searched for any missing values, establishing that there were none. Several graphs were produced for all variables, including monthly boxplots, distribution graphs and timeseries line graphs. Extreme weather analysis also highlighted any data in the top 5th percentile.

The main trends highlighted by the EDA were that there was more variation in solar flux during Spring and Summer months, temperature was increasing over time by approximately 3 degrees Celsius and that extreme weather would increase in the future. Extreme heat (>25 degrees Celsius) became greater and more frequent, whilst extreme precipitation showed much higher spikes.

Some main challenges included establishing variables, namely PRSN which wasn’t provided initially. We were required to research this and establish the variable meaning ourselves. I looked at several online sources, eventually settling on snowfall precipitation rate, as this seemed most appropriate. Another option was snowfall flux, but I didn’t feel it was appropriate here. Some data-conversion was also required to establish the geographical coordinate which was done in the later preprocessing stage. I tried to establish the geographical coordinate for the data but was unable to. Thankfully, another member of the team established the requirement for conversion and after this I was able to plot the point on an overlay of a UK map.

On reflection, the EDA provided good context for the project, but several analyses didn’t provide much insight. In future, more EDA could be done after pre-processing of the data to establish any trends which may not be apparent whilst analysing the raw data. This could be done by standardising or normalising the data or removing noise from the dataset to provide a clearer picture of the data.

Overall, I feel like I gave a good contribution to the project from an administrative and technical perspective, showing strong organisational and good teamwork skills. In future, I feel that more quality assurance of each other’s work could help to elevate the output. Our presentation focused on a Pearson correlation between variables, whereas Spearman’s Rank may have been more appropriate, due to the dataset’s nonlinearity. However, I feel that the overarching quality of the work provided by our group was of a decent standard.



# 2 Pre-processing - Madeleine Carnell
The preprocessing phase was essential to ensuring data integrity, and I took the initiative to lead this stage, focusing on data cleaning, transformation, and consistency. My contributions included interpolating negative precipitation and snowfall values, converting temperature from Kelvin to Celsius, and correcting longitude formatting to identify the dataset’s location. I also extracted new time-based features for seasonal analysis and modified variable names to enhance clarity for stakeholders such as climate researchers and policymakers. During this process, I overlooked an error in the QBOT variable, which had been misidentified by another group member. Failing to double-check this assumption led to an inaccuracy later pointed out by our lecturer. This experience underscored the importance of rigorous validation and domain-specific verification when handling environmental data. However, working through these challenges strengthened my understanding of interpolation techniques and the complexities of data integrity.

Furthermore, I enhanced our exploratory data analysis (EDA) as I wanted to provide a clearer understanding of long-term climate trends within the dataset. To achieve this, I created two additional visualisations: one tracking temperature changes over time and another analysing precipitation trends. These visualisations incorporated key statistical techniques to improve trend interpretation and minimise noise. This process reinforced my understanding of data smoothing and trend analysis. I initially considered more complex methods but opted for simpler aggregation techniques to maintain clarity. I enjoyed the creative aspect of visualising data, but I found it frustrating that without external comparisons, it was difficult to determine whether the dataset reflected a plausible climate scenario.

To address this, I conducted independent research, drawing insights from the CHESS SCAPE Regional Climate Model (RCM) to contextualise our findings. This comparison validated the projected 3°C temperature increase in our dataset, aligning it with moderate climate scenarios that assume no significant mitigation efforts. Given the limited background provided on our dataset, I felt it was critical to assess its credibility—without verification, there was no guarantee that our data reflected realistic climate projections. This exploration also provided insight into potential preprocessing steps, such as downscaling and bias correction, that our dataset may have undergone.

In addition to my technical contributions, I took on an administrative role by coordinating room bookings for our meetings. While I appreciated the detective-like aspect of tracing the dataset’s origins and correcting inaccuracies, I would like to be more involved in future analytical work. I also believe that greater engagement from all team members throughout the project would lead to stronger, more well-rounded outcomes.



# 3 Correlation Analysis  - Chenyu Ma
In this project, after discussions with my team members, I took responsibility for conducting the correlation analysis among the variables and establishing the relevant models. To begin, To begin, I employed both correlation and linear regression to explore the relationships between various meteorological variables and temperature. Our scatter plot matrix and kernel density estimates indicate that most variables have a positively skewed distribution, and overall, the linear correlations are weak. Notably, temperature and humidity show a significant positive correlation. Unexpectedly, we observed a positive correlation between temperature and the variable originally assumed to represent humidity.Given that meteorological principles suggest temperature and humidity should be negatively correlated, this discrepancy indicates that our definition of QBOT is likely mistaken—it does not represent humidity but rather water vapor content. This realization has prompted us to revisit the terminology and further investigate the variable through additional literature.

Delving deeper, the univariate linear regression showed that QBOT explained a substantial portion of temperature variation (R² = 0.768), compared to shortwave radiation (R² = 0.367). However, the scatter plots revealed a curved, nonlinear relationship between temperature and QBOT, implying that the association might be better captured using Spearman correlation or other nonlinear modeling techniques rather than a simple linear model. Moreover, the multivariate regression, which included Shortwave radiation and QBOT, increased the explained temperature variance to 93%, with low multicollinearity as indicated by VIF values near 1.  

Reflecting on my contributions, I established the GitHub repository and maintained effective communication with the team to coordinate data processing and model selection, while also playing a key role in data visualization. This experience has highlighted several challenges: the misinterpretation of a term, the need for a modeling strategy that accommodates nonlinear relationships, and the importance of ensuring that our analytical results align with realistic principles.

Looking forward, I think future research should not only focus on the individual characteristics of each variable but also rigorously assess whether the relationships between them conform to real-world expectations. It will be important to carefully analyze variable distributions and test multiple modeling approaches rather than relying solely on a single method. Furthermore, effective communication and collaboration among team members are crucial, because good communication and assistance can reduce project errors. In the context of this project, further investigation into the influence of other variables on temperature, the incorporation of time series trends, and the exploration of advanced modeling techniques—such as alternative regression models and deep learning approaches—could significantly enhance our predictive capability and the overall robustness of our analysis.



# 4 Result & Future Work - Wanglu Yu
During this project, I realised that I need to be more relaxed when communicating in a group, especially when expressing ideas in English, to avoid compromising my communication due to nervousness. This is crucial for my future work in an English-speaking environment.

At the same time, I gained a deep understanding of the importance of clear expression. When sharing code and presenting ideas, it is not enough to show the results. The necessary explanations will help team members better understand my thinking and work together to optimise the project. 

Since I only provided the code for the multivariate graph but did not explain in detail the visualisation logic for adjusting the size and colour of the data points, the team ultimately did not adopt the suggestion. Meanwhile, the professor suggested the same approach in his feedback. This made me realise that valuable ideas can also be ignored if they lack clear explanation and effective communication.

In addition, this project exposed me to concepts and terms in environmental data science and deepened my understanding of data analysis methods. During our analyses, we found that temperature was highly correlated with several environmental variables and attempted to determine possible future weather extremes through rainfall. However, from the professor's feedback to other groups, I realised that a clear definition of 'extreme weather' is needed to determine whether it constitutes an extreme weather trend. In addition, during the presentation, the professor pointed out that we incorrectly use humidity, due to misunderstanding the meaning of humidity and QBOT. These two incidents made me realise that having a clear understanding of variable definitions is crucial to ensuring accurate analysis and avoiding conceptual misunderstandings in future research. A conceptual mistake can have a significant impact on the direction of a project, so it is essential to check the concepts before initiating any future projects.

In this project, I participated in multiple sessions and contributed ideas and efforts proactively:
I took the initiative in creating a PowerPoint presentation, although it was not adopted by the group in the final version, the process honed my ability to assign topics.
I communicated proactively with group members about analysis ideas. I suggested adding multivariate graphs based on univariate graphs to gain a more comprehensive view of the relationships between variables. In the first meeting, I also raised a suggestion about whether the correlation matrix should use Pearson or Spearman correlation.
I suggested using VIF (Variance Inflation Factor) and R² for multicollinearity analysis. I also provided the code, which will be useful for feature selection when building a model in the future.
Furthermore, I proposed solutions for further work, making detailed suggestions for specific achievable parts, such as optimising feature engineering and enhancing modelling methods. As a result of these contributions, I have not only improved my data analysis skills and understanding of environmental science, but also honed my communication, teamwork and problem-solving skills.
